{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccd6af4b-ae55-41ea-890b-77db1f9c40be",
   "metadata": {},
   "source": [
    "# Prompt Engineering\n",
    "Prompt engineering is the process of designing and refining prompts to improve AI model performance by providing clear, specific, and well-structured instructions.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f89fb6ed-6eae-4dab-aa6b-7132ff2a5303",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 2) (3170393423.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    AZURE_OpenAI_ENDPOINT= \"\u001b[0m\n\u001b[1;37m                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "# Add you code here\n",
    "AZURE_OpenAI_ENDPOINT= \"\n",
    "AZURE_OpenAI_KEY= \"\"\n",
    "AZURE_OpenAI_MODEL= \"\"\n",
    "API_Version = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5a3577-b275-4ec7-bbe0-eb45635e1ae1",
   "metadata": {},
   "source": [
    "## Define Azure OpenAI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2de9ec9-51e7-4474-9fb4-59037ad56c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# Add code here\n",
    "client = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7c8908-2682-435b-b737-34a9c70df02f",
   "metadata": {},
   "source": [
    "# Scenario:\n",
    "Imagine you're a data scientist hired by a leading life sciences company specializing in global medical research. The company is launching an AI-driven translation tool to streamline the translation of complex scientific and clinical documents. Your task is to leverage Azure OpenAI Service to create a highly accurate, context-aware translation system tailored for life sciences, focusing on precise terminology, natural language, and contextual nuances specific to the industry. <br>\n",
    "\n",
    "Throughout these exercises, you will build, refine, and customize prompts to meet industry-specific translation needs. By the end, you’ll have a functional prototype with basic translation capabilities and the ability to recognize specialized terminology."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b6b408-637f-4794-869e-002def2f3fee",
   "metadata": {},
   "source": [
    "## Exercise 1: Basic Setup and Execution\n",
    "In this exercise, you'll initialize the translation tool and test a simple translation. This sets the foundation for more advanced features.\n",
    "\n",
    "1. **Create Message Structure**: Develop the structure for messages you will send to the Azure OpenAI model.\n",
    "2. **Design the Initial Prompt**: Write an initial prompt that instructs the model to perform a straightforward translation task.\n",
    "3. **Define Model Parameters**: Specify the list of arguments needed, including the Azure OpenAI model name you are using.\n",
    "4. **Set Parameters for Responses**:\n",
    "   - **Token Limit**: Limit the response to 1,000 tokens to maintain concise outputs.\n",
    "   - **Temperature**: Set the temperature to 0.5 for balanced creativity and consistency.\n",
    "5. **Run the API Call**: Call the Azure OpenAI Chat Completion API, passing in the parameters and prompt.\n",
    "\n",
    "**Hint**: Use api_params to easily reference your arguments in the API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24fdd3f7-a631-4e7e-b5f4-f9f267a8510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AI_translation1(AI_client, AI_model):\n",
    "    # Add code here\n",
    "    messages= []\n",
    "\n",
    "    # Add code here\n",
    "    api_params = {\n",
    "        \"model\": AI_model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": \"\",\n",
    "        \"max_tokens\": \"\"\n",
    "        }\n",
    "\n",
    "    # Add code here\n",
    "    response = \"\"\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf0dba71-a62b-4ee4-b68f-2b663ee6aa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \"Wie ist es?\" translates to \"How is it?\" in English.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Response: \" + AI_translation1(client, AZURE_OpenAI_MODEL) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901aba17-c27b-43c4-9850-134fdfbc5480",
   "metadata": {},
   "source": [
    "## Exercise 2: Enhancing the Prompt\n",
    "Now, improve the translation prompt to make the tool more adaptive and precise.\n",
    "\n",
    "1. **Detect Source Language Automatically**: Update the prompt to instruct the model to detect the source language without explicit input.\n",
    "2. **Specify Target Language**: Include clear instructions for the target language of the translation.\n",
    "3. **Restrict to Translation Only**: Ensure that the translation output contains only the translated text with no comments or additional text.\n",
    "4. **Add an Example**: Provide at least one example translation in the prompt to guide the model’s behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace1f216-1399-4fb5-855c-37146b3bd714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AI_translation2(AI_client, AI_model):\n",
    "    # Add code here\n",
    "    system_prompt = \"\"\n",
    "    user_prompt = \"\"\n",
    "    messages= [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    # Add code here\n",
    "    api_params = {\n",
    "        \"model\": AI_model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 1000\n",
    "        }\n",
    "\n",
    "    # Add code here\n",
    "    response = AI_client.chat.completions.create(**api_params)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8433cb-8481-420e-bf66-ad8bfc4138fc",
   "metadata": {},
   "source": [
    "## Exercise 3: Customizing for the Life Sciences Domain\n",
    "As the tool progresses, it should be tailored to handle industry-specific terminology, ensuring professional-level quality for life sciences translations.\n",
    "\n",
    "1. **Contextualize the Prompt for Life Sciences**: Add contextual details to the prompt, specifying that translations are intended for the life sciences field.\n",
    "2. **Adapt for Specialized Terminology**: Modify the prompt to make translations more accurate for specialized medical and scientific terms.\n",
    "3. **Refine for End Users**: Consider the end users (e.g., medical researchers, clinicians) and adjust the translation style accordingly to sound authoritative and natural.\n",
    "4. **Handle Sensitive Elements**: Ensure elements like names, dates, codes, and identifiers remain unaltered if required.\n",
    "5. **Check for Naturalness**: Evaluate if the translation sounds grammatically correct and is fluent for a professional setting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10e2bb0e-26e0-42b2-8c60-ca5638317a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AI_translation3(AI_client, AI_model):\n",
    "    # Add code here\n",
    "    system_prompt = \"\"\n",
    "    user_prompt = \"\"\n",
    "    messages= [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    # Add code here\n",
    "    api_params = {\n",
    "        \"model\": AI_model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 1000\n",
    "        }\n",
    "\n",
    "    # Add code here\n",
    "    response = AI_client.chat.completions.create(**api_params)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb464c7-5bf8-4937-8f30-41d79ebc26c3",
   "metadata": {},
   "source": [
    "## Exercise 4: Integrating External Input for Custom Terminology\n",
    "Each life sciences company has unique terminologies, acronyms, and abbreviations. This exercise enables you to import these terms to customize translations further.\n",
    "\n",
    "1. **Import Custom Terminology**: Use the Excel file `acronyms.xlsx`, which contains specialized acronyms and abbreviations.\n",
    "2. **Read Acronyms into the Model**: Use the provided `read_acronyms()` function to load and process the list of acronyms from the Excel file.\n",
    "3. **Incorporate Acronyms into Translations**: Include the loaded acronyms in your prompt, instructing the model to use them accurately during translation.\n",
    "4. **Adapt Translations Based on Acronyms**: Guide the model to translate the acronyms accurately or retain them as needed, ensuring consistency in the target language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4363a79-e086-49f4-ba93-d62075b5ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_acronyms(input_acronyms):\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    acronyms = df.columns[0]\n",
    "    descriptions = df.columns[1]\n",
    "\n",
    "    # Generate the text output\n",
    "    output_text = \"\"\n",
    "    for i, row in df.iterrows():\n",
    "        output_text += f\"{i+1}- {row[acronyms]} stands for {row[descriptions]}\\n\"\n",
    "\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797a5ba5-8b75-462c-92cc-9c5365879c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AI_translation4(AI_client, AI_model):\n",
    "    # Add code here\n",
    "    system_prompt = \"\"\n",
    "    user_prompt = \"\"\n",
    "    messages= [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    # Add code here\n",
    "    api_params = {\n",
    "        \"model\": AI_model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 1000\n",
    "        }\n",
    "\n",
    "    # Add code here\n",
    "    response = AI_client.chat.completions.create(**api_params)\n",
    "    return response.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
